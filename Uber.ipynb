{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5dc461",
   "metadata": {},
   "source": [
    "#Predict the price of the Uber ride from a given pickup\n",
    "point to the agreed drop-off location. Perform following\n",
    "tasks:\n",
    "1. Pre-process the dataset.\n",
    "2. Identify outliers.\n",
    "3. Check the correlation.\n",
    "4. Implement linear regression and random forest regression models.\n",
    "5. Evaluate the models and compare their respective scores like R2, RMSE, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac78b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22738bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe73df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(\"uber.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da313ede",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1. Pre-process the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ac66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6286e7",
   "metadata": {},
   "source": [
    "### Filling Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25941c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbcd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dropoff_latitude'].fillna(value=df['dropoff_latitude'].mean(),inplace = True)\n",
    "df['dropoff_longitude'].fillna(value=df['dropoff_longitude'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a86e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'key'], axis= 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3e347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d966e",
   "metadata": {},
   "source": [
    "### Column pickup_datetime is in wrong format (Object). Convert it to DateTime Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'pickup_datetime' is your column\n",
    "df.pickup_datetime = pd.to_datetime(df.pickup_datetime, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70151559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separating the date and time into separate columns for more usability\n",
    "df= df.assign(\n",
    "            second = df.pickup_datetime.dt.second,\n",
    "            minute = df.pickup_datetime.dt.minute,\n",
    "            hour = df.pickup_datetime.dt.hour,\n",
    "            day= df.pickup_datetime.dt.day,\n",
    "            month = df.pickup_datetime.dt.month,\n",
    "            year = df.pickup_datetime.dt.year,\n",
    "            dayofweek = df.pickup_datetime.dt.dayofweek\n",
    "            )\n",
    "df = df.drop('pickup_datetime',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e182e4",
   "metadata": {},
   "source": [
    "### Checking outliers and flling them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59032e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind = \"box\",subplots = True,layout = (7,2),figsize=(15,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def remove_outlier(df1 , col):\n",
    "    Q1 = df1[col].quantile(0.25)\n",
    "    Q3 = df1[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_whisker = Q1-1.5*IQR\n",
    "    upper_whisker = Q3+1.5*IQR\n",
    "    df1[col] = np.clip(df1[col] , lower_whisker , upper_whisker)\n",
    "    return df1\n",
    "\n",
    "def treat_outliers_all(df1 , col_list):\n",
    "    for c in col_list:\n",
    "        df1 = remove_outlier(df1 , c)\n",
    "    return df1\n",
    "\n",
    "# Assuming that 'df' is your DataFrame and 'df.columns' is the list of columns in your DataFrame\n",
    "df = treat_outliers_all(df , df.columns)\n",
    "\n",
    "# Plotting boxplots for all columns in the DataFrame\n",
    "df.plot(kind = \"box\", subplots = True, layout = (7,2), figsize=(15,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3d6ec",
   "metadata": {},
   "source": [
    "### Function to find Corrrlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d141be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "corr.style.background_gradient(cmap='BuGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f40266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import haversine as hs\n",
    "\n",
    "# Initialize an empty list to store travel distances\n",
    "travel_dist = []\n",
    "\n",
    "# Iterate through the DataFrame rows to calculate distances\n",
    "for pos in range(len(df['pickup_longitude'])):\n",
    "    long1, lati1, long2, lati2 = df['pickup_longitude'][pos], df['pickup_latitude'][pos], df['dropoff_longitude'][pos], df['dropoff_latitude'][pos]\n",
    "    loc1 = (lati1, long1)\n",
    "    loc2 = (lati2, long2)\n",
    "    c = hs.haversine(loc1, loc2)\n",
    "    travel_dist.append(c)\n",
    "\n",
    "# Assign the calculated distances to a new column in the DataFrame\n",
    "df['dist_travel_km'] = travel_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52558dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding inccorect latitude (Less than or greater than 90) and longitude (greater than or less than 90)\n",
    "incorrect_coordinates = df.loc[\n",
    "(df.pickup_latitude > 90) |(df.pickup_latitude < -90) |\n",
    "(df.dropoff_latitude > 90) |(df.dropoff_latitude < -90) |\n",
    "(df.pickup_longitude > 180) |(df.pickup_longitude < -180) |\n",
    "(df.dropoff_longitude > 90) |(df.dropoff_longitude < -90)\n",
    "]\n",
    "df.drop(incorrect_coordinates, inplace = True, errors = 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a62289",
   "metadata": {},
   "source": [
    "### Dividing the dataset into features and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']]\n",
    "y = df['fare_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245742f",
   "metadata": {},
   "source": [
    "### Dividing the dataset into training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108476ce",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c11288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa50af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.intercept_ #To find the linear intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.coef_ #To find the linear coeeficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = regression.predict(X_test) \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e65995",
   "metadata": {},
   "source": [
    "### Metrics Evaluation using R2, Mean Squared Error, Root Mean Sqared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score (y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ede332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE = mean_squared_error(y_test,prediction)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The equation RMSE = np.sqrt(MSE) is used to calculate the Root Mean Square Error (RMSE) from the Mean Squared Error (MSE).\n",
    "RMSE = np.sqrt(MSE)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160380dd",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46941e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d21f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric evaluation for random forest\n",
    "R2_Random = r2_score(y_test,y_pred)\n",
    "print(R2_Random)\n",
    "\n",
    "MSE_Random = mean_squared_error(y_test,y_pred)\n",
    "print(MSE_Random)\n",
    "\n",
    "RMSE_Random = np.sqrt(MSE_Random)\n",
    "print(RMSE_Random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fc6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
